---
title: "Por QU칄 tu MODELADO FALLA (No es lo que Piensas) 游댠"
date: 2025-05-27
summary: El 60% de los proyectos de datos fallan no por la tecnolog칤a, sino por decisiones de modelado incorrectas al inicio. Descubre los tres pilares del modelado efectivo, la importancia de la granularidad y un framework pr치ctico para asegurar la escalabilidad de tu arquitectura.
tags:
  ["data modeling", "architecture", "star schema", "granularity", "framework"]
author: "Omar Valdez G"
weight: 2
ShowToc: true
draft: false
---

### TL;DR

El modelado de datos es el plano arquitect칩nico que determina el 칠xito o el fracaso de un proyecto. Muchos fallan por crear "tablas gigantes" o por no considerar la evoluci칩n del negocio. Para evitarlo, debes modelar para el **acceso** (no solo el almacenamiento), preparar el modelo para la **evoluci칩n**, y contextualizar seg칰n el caso de uso (Transaccional, BI o Machine Learning). Recuerda siempre guardar el nivel m치s alto de granularidad posible.

Video en Youtube: [click aqu칤](https://youtu.be/hwq_fZJerJs?si=fxA5UFwi4IaCi_Vv)

### Intro

Te voy a contar algo que aprend칤 de la manera dif칤cil. El 60% de los proyectos de datos que fallan, no lo hacen por la tecnolog칤a elegida ni por el volumen de datos, sino por una decisi칩n que toman al inicio: el modelado.

El modelado de datos no es solo dibujar cajitas y flechas; es el plano arquitect칩nico de todo lo que vas a construir despu칠s. Si est치s construyendo dashboards, implementando Machine Learning o simplemente almacenando datos, tu 칠xito depende de esto. Hoy veremos los errores que cuestan millones y un framework pr치ctico para modelar datos que funcionan en el mundo real.

### El Error de la "Tabla Gigante": El Caso E-Learning

Imagina una plataforma de e-learning que evaluaste con 500 usuarios. Seis meses despu칠s, gracias a una campa침a de marketing, crecen a 20,000 usuarios. El sistema se vuelve in칰til, lento y ca칩tico, a pesar de haber invertido m치s de $150,000 en infraestructura.

쮼l culpable? No fue el servidor. Fue el modelado.

El error com칰n es crear una 칰nica tabla gigante (por ejemplo, `cursos_contenido`) donde se acumula todo.

- Se agregan campos de usuario (`user_id`, `username`) dentro de la tabla de cursos.
- Con el tiempo, se agregan m치s columnas y la tabla se llena de valores nulos y desorden.
- Al volverse inmanejable, alguien decide crear _otra_ tabla de usuarios paralela porque la original es dif칤cil de consultar.
- Resultado: Analistas y Cient칤ficos de Datos no saben c칩mo hacer `joins`, los IDs no coinciden y se pierde la integridad.

Es como construir una casa hermosa sin cimientos. Todo parece perfecto hasta la primera tormenta. Reconstruir los cimientos con la casa habitada es 10 veces m치s costoso que hacerlo bien desde el principio.

### Los Tres Pilares para Evitar Desastres

En el mundo real, con plazos limitados, hay tres pilares que marcan la diferencia entre un modelo fr치gil y uno robusto:

#### 1. Modela para el Acceso, no solo para el Almacenamiento

El verdadero valor de los datos est치 en c칩mo recuperas y usas la informaci칩n, no en c칩mo la guardas.

- **Enfoque Novato:** Una tabla gigante de "Productos" con 200 columnas (categor칤as, precios, inventario, proveedor).
- **Enfoque Experto:** Varias tablas m치s peque침as e interconectadas, optimizadas para las b칰squedas m치s frecuentes.

**Mito vs. Realidad:**

- _Mito:_ "Si tengo todo en una tabla es m치s f치cil."
- _Realidad:_ Las consultas complejas en tablas gigantes se vuelven exponencialmente lentas.
- **Consejo:** Antes de dise침ar, preg칰ntate: 쮺u치les son las 5 o 10 consultas m치s frecuentes que se har치n? Optimiza para esas.

#### 2. La Evoluci칩n es Inevitable. Prep치rate

El negocio cambia, tus datos cambian y tus necesidades tambi칠n. Tu modelo debe adaptarse sin demolerlo todo.

- **Reglas de Oro:**
  - No asumas que conoces todos los datos futuros.
  - Usa IDs que nunca cambien, aunque todo lo dem치s en la fila s칤 lo haga.
- Redise침ar un modelo despu칠s costar치 much칤simo m치s que hacerlo bien desde el inicio.

#### 3. Contextualiza seg칰n el Caso de Uso

No existe un modelo perfecto universal. El mismo conjunto de datos se modela diferente seg칰n qui칠n lo consuma:

- **Caso Transaccional (OLTP):** M칰ltiples tablas peque침as normalizadas (3NF). El foco es la consistencia y la integridad de los datos (ej. Clientes, 칍rdenes, Detalles).
- **Caso de An치lisis / Business Intelligence (OLAP):** Modelo Estrella (_Star Schema_). Los hechos (_Facts_) en el centro (90% del volumen) rodeados de dimensiones (_Dimensions_) que describen la informaci칩n. Optimizado para preguntas puntuales de an치lisis.
- **Caso de Machine Learning:** Datos desnormalizados. Aqu칤 s칤 conviene una tabla ancha (wide table) para evitar `joins` costosos durante el entrenamiento. Incluye campos precalculados (ej. "gasto total por cliente") para facilitarle la vida al cient칤fico de datos.

### Decisiones Estructurales Clave

Una vez claros los pilares, hay dos decisiones t칠cnicas fundamentales: c칩mo conectas los datos y su nivel de detalle.

#### Relaciones

- **1 a 1:** Un usuario tiene un perfil.
- **1 a Muchos:** Un cliente hace muchas 칩rdenes (la relaci칩n m치s com칰n). Un error aqu칤 rompe el historial del cliente.
- **Muchos a Muchos:** Siempre usa una tabla intermedia y dale atributos 칰tiles a esa relaci칩n.

#### Granularidad

La granularidad es el nivel de detalle de una fila en tu tabla. Existen tres niveles:

1.  **Baja (Detallada):** Transaccional (cada clic de usuario).
2.  **Media:** Agregada para reportes r치pidos.
3.  **Alta:** Super agregada (ventas totales por pa칤s).

**La Regla de Oro de la Granularidad:**
La tendencia siempre es de Baja hacia Alta (agregar). **Nunca podr치s desagregar.**
Si guardas solo ventas totales por tienda, luego no podr치s analizar la canasta de compra por cliente. Incluso si ocupa m치s espacio, almacena siempre el nivel m치s granular posible. El costo de almacenamiento es barato comparado con el costo de perder la oportunidad de an치lisis por falta de detalle.

### T칠cnicas de Optimizaci칩n

Para que tu modelo sea r치pido y manejable en el tiempo:

#### 1. Manejo del Tiempo (Temporalidad)

Cuando un dato cambia en el mundo real (ej. el precio de un producto), no lo sobrescribas. Usa la t칠cnica de _Slowly Changing Dimensions_ (SCD):

- Marca el registro antiguo como inactivo (asigna fecha fin).
- Inserta un nuevo registro con la informaci칩n actualizada y fecha inicio.
  Esto te permite analizar el hist칩rico y ver qu칠 promociones funcionaron en el pasado.

#### 2. Particionamiento

Imagina tener 5 a침os de ventas en una sola tabla. Si preguntas por las ventas del mes pasado, la base de datos escanea los 5 a침os.
Si particionas la tabla por mes, la base de datos sabe exactamente d칩nde est치 ese mes y lee solo esa peque침a porci칩n. Es el turbo para tus consultas.

### Framework Pr치ctico de Modelado

쮺칩mo juntamos todo esto? Sigue este proceso de 5 pasos:

1.  **Define Objetivos de Negocio:** 쯈u칠 preguntas clave responder치n los datos? 쯈ui칠nes son los usuarios? (Transacciones r치pidas vs. An치lisis complejo vs. ML).
2.  **Identifica Patrones de Acceso:** 쮿abr치 m치s lectura o escritura? 쮺u치les son las consultas cr칤ticas? 쮺u치l es el volumen de datos esperado a 1 o 5 a침os?
3.  **Prototipa para Casos Extremos:** Piensa qu칠 pasa si los datos se multiplican por 10 o 100. 쯈u칠 tan f치cil es a침adir nueva informaci칩n sin romper el esquema?
4.  **Valida con Datos Reales:** No te f칤es solo de datos de prueba sint칠tica. Carga vol칰menes realistas y mide los tiempos de tus consultas clave.
5.  **Dise침a para Evolucionar:** Documenta por qu칠 tomaste ciertas decisiones. Planifica revisiones peri칩dicas (ej. cada 12 meses) para ver si el modelo sigue alineado con la estrategia.

### Conclusi칩n

La mayor칤a de los modelos no fallan el d칤a uno, fallan uno o dos a침os despu칠s cuando el negocio ha cambiado. Pensar en la evoluci칩n desde el inicio es la clave.

El modelado de datos es un arte y un equilibrio entre teor칤a y necesidades pr치cticas. Si te quedas con algo de este video, que sea esto: **Modela pensando en c칩mo se van a acceder los datos y c칩mo van a evolucionar con el tiempo, no solo en c칩mo los vas a almacenar hoy.** Los equipos futuros de BI, Analistas y Machine Learning te lo agradecer치n.

&nbsp;
